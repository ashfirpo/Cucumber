{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Firpo_Ayelen_Ejercicio_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eetimUW7CeF"
      },
      "source": [
        "#Ejercicio 2: Image Mirroring"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thB_uROg698d"
      },
      "source": [
        "##1. Introducción\n",
        "<justify>En este cuaderno, vamos a realizar el espejado de una imagen de manera horizontal [2]. Este tratamiento de la imagen se hará de manera secuencial y en paralelo optimizada con CUDA [4].\n",
        "\n",
        "El algoritmo que se desarrollará a continuación está basado en la transposición de matrices [1]. La diferencia está en que solamente se hará sobre el eje x, a modo de que quede con el efecto de espejado horizontal y no realmente transpuesta completa.\n",
        "\n",
        "Matemáticamente hablando, se procederá a realizar la siguiente operación:\n",
        "</justify>\n",
        "\n",
        "<center>$imagen[x_i][y]= imagen[n -1 - x_i][y]$    [3]</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V1trONCBvjgL"
      },
      "source": [
        "<justify>Siendo *imagen* la imagen en forma de matriz, $x_i$ va a ser la posición del eje x que se va a trasponer, *n* es la cantidad total de elementos sobre el eje x (es decir, el ancho). Nótese que *y* queda fijo en toda la operación, ya que los valores sobre el eje y se mantienen debido a que es una transposición solamente sobre el eje x.\n",
        "</justify>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGQydOLI7Ihr"
      },
      "source": [
        "##2. Armado del ambiente\n",
        "Para el armado del ambiente, es necesario instalar CUDA [5] e importar una imagen a elección."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGBt1R9pw0Ws"
      },
      "source": [
        "###2.1. Instalación de CUDA\n",
        "Procedemos a instalar CUDA en el notebook con el siguiente comando:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVxsoCgWrzzH"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYoFuvRSxBP8"
      },
      "source": [
        "###2.2. Importar imagen\n",
        "Solicitamos al usuario que ingrese la URL de una imagen a elección. El formato de la imagen tiene que ser **.jpg** o **.jpeg** [2]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2unIqGA_xNzd"
      },
      "source": [
        "#----- Usamos esta parte para que el usuario ingrese los parámetros -----\n",
        "#@title Ingrese la dirección URL de una imagen .jpg / .jpeg { vertical-output: true }\n",
        "\n",
        "imagen_url = \"https://upload.wikimedia.org/wikipedia/commons/c/c3/NGC_4414_%28NASA-med%29.jpg\" #@param {type: \"string\"}\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Se dejan algunas imágenes de prueba:\n",
        "\n",
        "Cuadrada: https://miro.medium.com/max/400/0*C9qMhSqy-GdqP5aM.jpg\n",
        "Más ancha: https://www.mundoperros.es/wp-content/uploads/2019/03/pitbull-terrier-feliz.jpg\n",
        "Más larga: https://i.pinimg.com/originals/ab/80/70/ab80707d85d8ef6d5e6ee81da05c30c7.jpg\n",
        "Súper grande: https://upload.wikimedia.org/wikipedia/commons/3/30/Amazona_aestiva_-upper_body-8a_%281%29.jpg\n",
        "\"\"\"\n",
        "\n",
        "if not (type(imagen_url) is str) or (imagen_url == \"\"):\n",
        "  raise TypeError(\"Se tiene que ingresar una dirección URL\")\n",
        "\n",
        "if not (imagen_url.endswith(\".jpg\") or imagen_url.endswith(\".jpeg\")):\n",
        "  raise Exception(\"La imagen tiene que ser en formato .jpg o .jpeg\")\n",
        "\n",
        "#Verificamos el parametro y tomamos la imagen\n",
        "!wget {imagen_url} -O imagen.jpg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JVlTJHe7L9T"
      },
      "source": [
        "##3. Desarrollo\n",
        "A continuación, se desarrollará el algoritmo para el espejado horizontal de la imagen del usuario."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtP1vnrA32r"
      },
      "source": [
        "#Importamos los módulos necesarios\n",
        "from datetime import datetime as dt\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image \n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "#CPU: empezamos a tomar el tiempo para el procesamiento\n",
        "tiempo_total = dt.now()\n",
        "\n",
        "#Definimos la función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "#CPU: Abrimos la imagen\n",
        "imagen_nombre = 'imagen.jpg'\n",
        "imagen = Image.open(imagen_nombre)\n",
        "\n",
        "#CPU: Tomamos las dimensiones de la imagen\n",
        "img_ancho, img_alto = imagen.size\n",
        "\n",
        "#CPU: convertimos la imagen en un array\n",
        "img_original_cpu = np.asarray(imagen)\n",
        "img_espejada_cpu = np.empty_like(img_original_cpu)\n",
        "#Este lo tenemos para copiar el resultado de GPU\n",
        "res_espejada_cpu = np.empty_like(img_original_cpu)\n",
        "\n",
        "#GPU: reservamos la memoria GPU\n",
        "img_original_gpu = cuda.mem_alloc(img_original_cpu.nbytes)\n",
        "img_espejada_gpu = cuda.mem_alloc(img_espejada_cpu.nbytes)\n",
        "\n",
        "#Copiamos la memoria a GPU\n",
        "cuda.memcpy_htod(img_original_gpu, img_original_cpu)\n",
        "cuda.memcpy_htod(img_espejada_gpu, img_espejada_cpu)\n",
        "\n",
        "#CPU: definimos la función kernel que va a ejecutar GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_mirror(int alto, int ancho, char *img_original, char *img_espejada)\n",
        "{\n",
        "  //Calculamos las coordenadas del thread en 2D\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "  int idy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "  \n",
        "  //Verificamos que los threads esten dentro de las dimensiones de la imagen\n",
        "  if(idx < ancho && idy < alto)\n",
        "  {\n",
        "    //Creamos los nuevos indices necesarios para espejar la matriz\n",
        "    int mirrorCol = ancho - idx - 1;\n",
        "    int index_x = idy * ancho * 3 + idx * 3;\n",
        "    int mirrorIdx = idy * ancho * 3 + mirrorCol * 3;\n",
        "    \n",
        "    //Tomamos cada uno de los 3 componentes RGB del pixel y lo copiamos\n",
        "    img_espejada[mirrorIdx] = img_original[index_x];         //R\n",
        "    img_espejada[mirrorIdx + 1] = img_original[index_x + 1]; //G\n",
        "    img_espejada[mirrorIdx + 2] = img_original[index_x + 2]; //B\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "#CPU: mostramos los atributos de la imagen\n",
        "print(\"Imagen: \", imagen_nombre, \" - \", imagen.mode, \" - [\", str(img_ancho), \", \", str(img_alto), \"]\")\n",
        "\n",
        "#CPU: generar la función kernel\n",
        "kernel = module.get_function(\"kernel_mirror\")\n",
        "\n",
        "\n",
        "#CPU: se define el tamaño de las dimensiones\n",
        "dim_hilo_x = 32\n",
        "dim_bloque_x = np.int((img_ancho + dim_hilo_x - 1) / dim_hilo_x)\n",
        "\n",
        "dim_hilo_y = 32\n",
        "dim_bloque_y = np.int((img_alto + dim_hilo_y - 1) / dim_hilo_y)\n",
        "\n",
        "print(\"Thread: [x: \", dim_hilo_x, \", y: \", dim_hilo_y, \"] | Bloque: [x: \", dim_bloque_x, \", y: \", dim_bloque_y, \"]\")\n",
        "print(\"Total de thread: [\", dim_hilo_x * dim_bloque_x,\n",
        "      \", \", dim_hilo_y * dim_bloque_y, \"]\",\n",
        "      \" = \", dim_hilo_x * dim_bloque_x * dim_hilo_y * dim_bloque_y)\n",
        "\n",
        "#Comenzamos a tomar el tiempo de ejecución de GPU\n",
        "tiempo_gpu = dt.now()\n",
        "\n",
        "#GPU: Mandamos la función kernel\n",
        "kernel(np.int32(img_alto), np.int32(img_ancho), img_original_gpu, img_espejada_gpu, block=(dim_hilo_x, dim_hilo_y, 1), grid=(dim_bloque_x, dim_bloque_y, 1))\n",
        "\n",
        "#Cortamos el tiempo de GPU\n",
        "tiempo_gpu = dt.now() - tiempo_gpu\n",
        "\n",
        "#CPU: copia el resultado desde la memoria de GPU\n",
        "cuda.memcpy_dtoh(res_espejada_cpu, img_espejada_gpu)\n",
        "\n",
        "#CPU: realizamos versión secuencial y empezamos a tomar el tiempo de ejecución del bucle\n",
        "tiempo_bucle_cpu = dt.now()\n",
        "\n",
        "for idy in range(0, img_alto):\n",
        "  for idx in range(0, img_ancho):\n",
        "      #Trasponemos solamente el eje x, dejamos igual al eje y\n",
        "      img_espejada_cpu[idy][idx] = img_original_cpu[idy][img_ancho - 1 - idx]\n",
        "\n",
        "\n",
        "#CPU: Cortamos el tiempo del bucle de CPU\n",
        "tiempo_bucle_cpu = dt.now() - tiempo_bucle_cpu\n",
        "\n",
        "#Mostramos las imagenes resultantes\n",
        "#Imagen original\n",
        "plt.figure()\n",
        "imgplot = plt.imshow(imagen)\n",
        "#Resultado de CPU\n",
        "plt.figure()\n",
        "imgplot = plt.imshow(img_espejada_cpu)\n",
        "#Resultado de GPU\n",
        "plt.figure()\n",
        "imgplot = plt.imshow(res_espejada_cpu)\n",
        "\n",
        "#CPU: Tomamos el tiempo de ejecución total\n",
        "tiempo_total = dt.now() - tiempo_total\n",
        "\n",
        "\n",
        "#CPU: Informamos los tiempos de ejecución\n",
        "print(\"Tiempo total: \", tiempo_en_ms(tiempo_total), \"ms\")\n",
        "print(\"Tiempo del bucle en CPU: \", tiempo_en_ms(tiempo_bucle_cpu), \"ms\")\n",
        "print(\"Tiempo de GPU: \", tiempo_en_ms(tiempo_gpu), \"ms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D475NXiF7OWD"
      },
      "source": [
        "##4. Tabla de pasos\n",
        "A continuación, realizaremos la tabla de pasos de ejecución del programa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjro79ouKKXt"
      },
      "source": [
        "<center>\n",
        "\n",
        "Procesador | Función | Detalle\n",
        "--- | --- | ---\n",
        "CPU | !pip install pycuda | Instalación de CUDA en el notebook actual\n",
        "CPU | @param | Lectura del la dirección URL de la imagen desde el formulario de Colab\n",
        "CPU | if... raise... | Controla que el parámetro pasado por el usuario sea válido\n",
        "CPU | wget imagen_url | Lectura de la imagen a procesar desde la dirección URL proporcionada\n",
        "CPU | import | Importa los módulos necesarios para la ejecución del programa\n",
        "CPU | matplotlib inline | Macro necesaria para mostrar las imágenes\n",
        "CPU | dt.now() | Toma el tiempo actual a modo de tiempo inicial de ejecución\n",
        "CPU | Image.open() | Abre el archivo de la imagen\n",
        "CPU | np.asarray(imagen) | Pasa la imagen al formato RAW\n",
        "CPU | np.empty_like() | Generación de los arrays necesarios para el resultado de las imagenes\n",
        "**GPU** | cuda.mem_alloc() | Reserva de la memoria para las imagenes en GPU\n",
        "**GPU** | cuda.memcpy_htod() | Copia el la imagen *img_original_cpu* a la memoria de GPU\n",
        "CPU | SourceModule() | Contiene el código del kernel\n",
        "CPU | module.get_function() | Convierte el texto del kernel en una función de Python\n",
        "CPU | dim_hilo_x, dim_hilo_y, dim_bloque_x, dim_bloque_y | Se calculan las dimensiones para la ejecución de 2D\n",
        "**GPU** | kernel() | Ejecución del kernel en GPU junto con los parámetros necesarios\n",
        "CPU | cuda.memcpy_dtoh() | Se copia desde la memoria GPU al CPU el resultado\n",
        "CPU | loop for | Aplica el algoritmo secuencial a la imagen *img_reflejada_cpu*\n",
        "CPU | plt.imshow() | Muestra las 3 imágenes en el orden: original, CPU y GPU\n",
        "CPU | print() | Informa los resultados por pantalla\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDN7XPKr7QgU"
      },
      "source": [
        "##5. Conclusiones\n",
        "Podemos notar que el mayor tiempo de ejecución lo tiene la ejecución en el ciclo *for* de CPU, en el cual se realiza el espejado de la imagen en cuestión.\n",
        "\n",
        "Esto es de esperarse, ya que es donde está el núcleo del programa que requiere más procesamiento. Cuanto más grandes sean las imágenes, más tiempo de ejecución va a requerir el ciclo *for*, ya que recorre mínimamente todas las posiciones de manera secuencial.\n",
        "\n",
        "Notamos que GPU mantiene los mismos tiempos para cualquier tamaño de imagen. Podemos ver que la cantidad de hilos que se crean es muy cercana al tamaño de la matriz, con lo que podríamos casi estimar que cada pixel está siendo procesado por un hilo en paralelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJBr8wo7Smr"
      },
      "source": [
        "##6. Bibliografía\n",
        "\n",
        "* [1]: [Nvidia - Transposición de matrices usando CUDA](https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/)\n",
        "* [2]: [Introducción a la Programación en CUDA](https://riubu.ubu.es/bitstream/handle/10259/3933/Programacion_en_CUDA.pdf;jsessionid=FC6394584537780DD2AD3F995FD075B4?sequence=1)\n",
        "* [3]: [Colab - Guía de markdowns](https://colab.research.google.com/notebooks/markdown_guide.ipynb#scrollTo=tPqPXAKKkzaM)\n",
        "* [4]: [Página oficial de CUDA para Python](https://pypi.org/project/pycuda/)\n",
        "* [5]: [Documentación de CUDA](https://documen.tician.de/pycuda/index.html)\n"
      ]
    }
  ]
}