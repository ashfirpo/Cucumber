{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Firpo_Ayelen_Ejercicio_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eetimUW7CeF"
      },
      "source": [
        "#Ejercicio 1: Función \"rot\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thB_uROg698d"
      },
      "source": [
        "##1. Introducción\n",
        "<justify>En este cuaderno, vamos a realizar la rotación de vectores en el plano de manera secuencial haciendo uso del procesador CPU, y su versión en paralelo optimizada con CUDA [4].\n",
        "\n",
        "El algoritmo que se desarrollará a continuación está basado en la función \"**rot**\" [1], perteneciente a la biblioteca BLAS de nivel 1 [2]. Dicha función procede a realizar las siguientes operaciones: </justify>\n",
        "\n",
        "<center>$x_i= c * x_i + s * y_i$    [3]</center>\n",
        "<center>$y_i = c * y_i - s * x_i$</center>\n",
        "\n",
        "Siendo *x* e *y* los vectores en cuestión, y *s* y *c* dos números escalares.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGQydOLI7Ihr"
      },
      "source": [
        "##2. Armado del ambiente\n",
        "Para el armado del ambiente, es necesario instalar CUDA [5]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVxsoCgWrzzH"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JVlTJHe7L9T"
      },
      "source": [
        "##3. Desarrollo\n",
        "Comenzamos, en primera instancia, con la solicitud de los parámetros:\n",
        "* \"**cantidad**\" es la cantidad de elementos de ambos vectores *x* e *y*.\n",
        "* \"**escalar_c**\" es el número *c* en la ecuación.\n",
        "* \"**escalar_s**\" es el número *s* en la ecuación.\n",
        "\n",
        "Por otra parte, en el código se realizará primero la versión en paralelo y luego la secuencial. De todos modos, se toman los tiempos en los momentos correspondientes, sin influir el orden en el que se presentan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtP1vnrA32r"
      },
      "source": [
        "#----- Usamos esta parte para que el usuario ingrese los parámetros -----\n",
        "#@title 3.1 Parámetro de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad = 51000 #@param {type: \"integer\"}\n",
        "escalar_c = 2 #@param {type:\"number\"}\n",
        "escalar_s = 5 #@param {type:\"number\"}\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "#Chequeamos que los parámetros tengan un valor correcto\n",
        "if cantidad <=0:\n",
        "  raise Exception(\"La cantidad de elementos de los vectores tienen que ser mayores a cero.\")\n",
        "if escalar_c <0:\n",
        "  raise Exception(\"El valor de 'c' tiene que ser mayor o igual a cero.\")\n",
        "if escalar_s <0:\n",
        "  raise Exception(\"El valor de 's' tiene que ser mayor o igual a cero.\")  \n",
        "\n",
        "#Importamos los módulos necesarios\n",
        "from datetime import datetime as dt\n",
        "import numpy as np\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "\n",
        "#CPU: empezamos a tomar el tiempo para el procesamiento\n",
        "tiempo_total = dt.now()\n",
        "\n",
        "#Definimos la función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "\n",
        "#CPU: definimos la memoria de los vectores\n",
        "x_cpu = np.random.randn(cantidad)\n",
        "x_cpu = x_cpu.astype(np.float32())\n",
        "res_x_cpu = np.empty_like(x_cpu)\n",
        "\n",
        "y_cpu = np.random.randn(cantidad)\n",
        "y_cpu = y_cpu.astype(np.float32())\n",
        "res_y_cpu = np.empty_like(y_cpu)\n",
        "\n",
        "#GPU: reservamos la memoria GPU\n",
        "x_gpu = cuda.mem_alloc(x_cpu.nbytes)\n",
        "y_gpu = cuda.mem_alloc(y_cpu.nbytes)\n",
        "\n",
        "#Copiamos la memoria a GPU\n",
        "cuda.memcpy_htod(x_gpu, x_cpu)\n",
        "cuda.memcpy_htod(y_gpu, y_cpu)\n",
        "\n",
        "#CPU: definimos la función kernel que va a ejecutar GPU\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void kernel_rot(int n, int c, int s, float *X, float *Y)\n",
        "{\n",
        "  int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  //Nos guardamos temporalmente los valores que vamos a reemplazar\n",
        "  float xi = 0.0;\n",
        "  float yi = 0.0;\n",
        "  \n",
        "  if(idx < n)\n",
        "  {\n",
        "    xi = X[idx];\n",
        "    yi = Y[idx];\n",
        "\n",
        "    X[idx] = c * xi + s * yi;\n",
        "    Y[idx] = c * yi - s * xi;\n",
        "  }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "#CPU: generar la función kernel\n",
        "kernel = module.get_function(\"kernel_rot\")\n",
        "\n",
        "\n",
        "#CPU: se define el tamaño de las dimensiones\n",
        "dim_hilo = 256\n",
        "dim_bloque = np.int((cantidad + dim_hilo - 1) / dim_hilo)\n",
        "print(\"Thread x: \", dim_hilo, \", Bloque x: \", dim_bloque)\n",
        "\n",
        "#Comenzamos a tomar el tiempo de ejecución de GPU\n",
        "tiempo_gpu = dt.now()\n",
        "\n",
        "#GPU: Mandamos la función kernel\n",
        "kernel(np.int32(cantidad), np.int32(escalar_c), np.int32(escalar_s), x_gpu, y_gpu, block=(dim_hilo, 1, 1), grid=(dim_bloque, 1, 1))\n",
        "\n",
        "#Cortamos el tiempo de GPU\n",
        "tiempo_gpu = dt.now() - tiempo_gpu\n",
        "\n",
        "#CPU: copia el resultado desde la memoria de GPU\n",
        "cuda.memcpy_dtoh(res_x_cpu, x_gpu)\n",
        "cuda.memcpy_dtoh(res_y_cpu, y_gpu)\n",
        "\n",
        "#CPU: realizamos la función \"dot\" y empezamos a tomar el tiempo de ejecución del bucle\n",
        "tiempo_bucle_cpu = dt.now()\n",
        "\n",
        "for idx in range(0, cantidad):\n",
        "  xi = x_cpu[idx]\n",
        "  yi = y_cpu[idx]\n",
        "\n",
        "  x_cpu[idx] = escalar_c * xi + escalar_s * yi\n",
        "  y_cpu[idx] = escalar_c * yi - escalar_s * xi\n",
        "\n",
        "\n",
        "tiempo_bucle_cpu = dt.now() - tiempo_bucle_cpu\n",
        "\n",
        "\n",
        "#CPU: Tomamos el tiempo de ejecución total\n",
        "tiempo_total = dt.now() - tiempo_total\n",
        "\n",
        "\"\"\"\n",
        "print(\"Resultado CPU:\")\n",
        "print(\"X: \", x_cpu)\n",
        "print(\"Y: \", y_cpu)\n",
        "print(\"-------------------------\")\n",
        "print(\"Resultado GPU:\")\n",
        "print(\"X: \", res_x_cpu)\n",
        "print(\"Y: \", res_y_cpu)\n",
        "print(\"-------------------------\")\n",
        "\"\"\"\n",
        "\n",
        "#CPU: Informamos los tiempos de ejecución\n",
        "print(\"Tiempo total: \", tiempo_en_ms(tiempo_total), \"ms\")\n",
        "print(\"Tiempo del bucle en CPU: \", tiempo_en_ms(tiempo_bucle_cpu), \"ms\")\n",
        "print(\"Tiempo de GPU: \", tiempo_en_ms(tiempo_gpu), \"ms\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D475NXiF7OWD"
      },
      "source": [
        "##4. Tabla de pasos\n",
        "A continuación, realizaremos la tabla de pasos de ejecución del programa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jjro79ouKKXt"
      },
      "source": [
        "<center>\n",
        "\n",
        "Procesador | Función | Detalle\n",
        "--- | --- | ---\n",
        "CPU | !pip install pycuda | Instalación de CUDA en el notebook actual\n",
        "CPU | @param | Lectura del tamaño de los vectores *x* e *y*, y de los escalares *c* y *s* desde el formulario de Colab\n",
        "CPU | if cantidad <=0 ... | Chequea que los parámetros sean válidos para el programa\n",
        "CPU | raise Exception ... | Lanza excepciones en el caso de fallar la condición anterior\n",
        "CPU | import | Importa los módulos necesarios para la ejecución del programa\n",
        "CPU | dt.now() | Toma el tiempo actual a modo de tiempo inicial de ejecución\n",
        "CPU | np.random.randn() | Inicializa los vectores *x* e *y*\n",
        "CPU | np.empty_like() | Generación de los arrays necesarios para el resultado de los vectores\n",
        "**GPU** | cuda.mem_alloc() | Reserva de la memoria para los vectores en GPU\n",
        "**GPU** | cuda.memcpy_htod() | Copia el array *x_cpu* e *y_cpu* a la memoria de GPU\n",
        "CPU | SourceModule() | Contiene el código del kernel\n",
        "CPU | module.get_function() | Convierte el texto del kernel en una función de Python\n",
        "CPU | dim_hilo, dim_bloque | Se calculan las dimensiones para la ejecución de 1D\n",
        "**GPU** | kernel() | Ejecución del kernel en GPU junto con los parámetros necesarios\n",
        "CPU | cuda.memcpy_dtoh() | Se copia desde la memoria GPU al CPU\n",
        "CPU | loop for | Aplica el algoritmo a los vectores *x* e *y*\n",
        "CPU | print() | Informa los resultados por pantalla\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDN7XPKr7QgU"
      },
      "source": [
        "##5. Conclusiones\n",
        "Podemos notar que el mayor tiempo de ejecución lo tiene la ejecución en el ciclo *for* de CPU, en el cual se realiza la rotación en el plano de los vectores *x* e *y*.\n",
        "\n",
        "Esto es de esperarse, ya que es donde está el núcleo del programa que requiere más procesamiento. Cuanto más grandes sean los vectores, más tiempo de ejecución va a requerir el ciclo *for*, ya que recorre todas las posiciones, además sabiendo que este ciclo posee una complejidad O(n), implicando que mínimamente va a recorrer todos los elementos de manera secuencial.\n",
        "\n",
        "Aún así, vemos que hay casos en los que tanto CPU como GPU podrían tardar de manera aproximada los mismos tiempos, como, por ejemplo, casos en los que los vectores tienen pocas cantidades de elementos (se ha probado con vectores de 6 elementos y se ha notado este caso en particular). De todos modos, la idea es procesar vectores de gran tamaño, ya que sería un desperdicio de HPC para dos vectores de 6 elementos cada uno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJBr8wo7Smr"
      },
      "source": [
        "##6. Bibliografía\n",
        "\n",
        "* [1]: [Intel - Rutinas y funciones BLAS nivel 1: Función \"rot\"](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions/cblas-rot.html#cblas-rot)\n",
        "* [2]: [Intel - Rutinas y funciones BLAS nivel 1](https://software.intel.com/content/www/us/en/develop/documentation/mkl-developer-reference-c/top/blas-and-sparse-blas-routines/blas-routines/blas-level-1-routines-and-functions.html)\n",
        "* [3]: [Colab - Guía para markdowns](https://colab.research.google.com/notebooks/markdown_guide.ipynb#scrollTo=tPqPXAKKkzaM)\n",
        "* [4]: [Página oficial de CUDA para Python](https://pypi.org/project/pycuda/)\n",
        "* [5]: [Documentación de CUDA](https://documen.tician.de/pycuda/index.html)\n"
      ]
    }
  ]
}